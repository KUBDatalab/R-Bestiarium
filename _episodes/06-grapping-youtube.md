---
# Please do not edit this file directly; it is auto generated.
# Instead, please edit 06-grapping-youtube.md in _episodes_rmd/
title: "Grabbing youtube videos"
teaching: 0
exercises: 0
questions:
  - "How to grab metadata from Youtube videos"
objectives:
  - "First learning objective. (FIXME)"
keypoints:
  - "First key point. Brief Answer to questions. (FIXME)"
---

  




Scraping comments from youtube is a speciel kind of problem, not covered here.
Hint: Selenium!

This is a relatively easy task to accomplish. We are "simply" using R to interact
with a thirdparty tool, youtube-dl, which can be found on [this page](https://youtube-dl.org/)

A nice thing about this tool, is that it supports a lot of other video services.

You will need to know exactly where to find the `youtube-dl` executable on your
computer.

On a windows machine it is typically called "youtube-dl.exe". On a Mac, "youtube-dl". 

Always. ALWAYS! be aware of any copyright issues. This tool must only be used
to download videos and metadata that you are actually allowed to download.

To take an example:


~~~
youtube-dl.exe https://www.youtube.com/watch?v=RG7c83sw6gk --write-info-json
~~~
{: .language-r}

MEN INTET VIRKER FÃ˜R DEN ER OPDATERET!

This will download the video, and save metadata for that video in a json-file.

There are a LOT of other options than "--write-info-json". 

One of the more useful is "--ignore-errors", that will continue to the
next video if a download error occurs, eg an unavailable video in a channel. 

Another is "--skip-download" that skips downloud of the video - sometimes 
we are only interested in the metadata.

Read the [documentation](https://github.com/ytdl-org/youtube-dl/blob/master/README.md#readme) 
for a complete list of options.

Let us produce som vectors containing:


Links til individual videos:

~~~
single_links <- c("https://www.youtube.com/watch?v=CayMeza487M",
                  "https://www.youtube.com/watch?v=dQw4w9WgXcQ",
                  "https://www.youtube.com/watch?v=kkyFzll6M10" )
~~~
{: .language-r}

Links to playlists (they look a bit different):

~~~
playlist <- c("https://www.youtube.com/playlist?list=PLxFN5K79aSHADipyJwISC4fVks2WXBLvH")
~~~
{: .language-r}


And links to channels, which have a third structure:

~~~
channel <- c("https://www.youtube.com/channel/UC2LVhJH_9cT2XKp0VAfsKOQ")
~~~
{: .language-r}


Combine them into a single vector containing everything we want to
download:


~~~
video_urls <- c(single_links, playlist, channel)
~~~
{: .language-r}


Now, generate the commandline command previously shown, for each element in the
vector:


~~~
video_urls 
~~~
{: .language-r}



~~~
[1] "https://www.youtube.com/watch?v=CayMeza487M"                             
[2] "https://www.youtube.com/watch?v=dQw4w9WgXcQ"                             
[3] "https://www.youtube.com/watch?v=kkyFzll6M10"                             
[4] "https://www.youtube.com/playlist?list=PLxFN5K79aSHADipyJwISC4fVks2WXBLvH"
[5] "https://www.youtube.com/channel/UC2LVhJH_9cT2XKp0VAfsKOQ"                
~~~
{: .output}


~~~
commands <- paste("youtube-dl.exe", video_urls, "--write-info-json --ignore-errors")
commands
~~~
{: .language-r}



~~~
[1] "youtube-dl.exe https://www.youtube.com/watch?v=CayMeza487M --write-info-json --ignore-errors"                             
[2] "youtube-dl.exe https://www.youtube.com/watch?v=dQw4w9WgXcQ --write-info-json --ignore-errors"                             
[3] "youtube-dl.exe https://www.youtube.com/watch?v=kkyFzll6M10 --write-info-json --ignore-errors"                             
[4] "youtube-dl.exe https://www.youtube.com/playlist?list=PLxFN5K79aSHADipyJwISC4fVks2WXBLvH --write-info-json --ignore-errors"
[5] "youtube-dl.exe https://www.youtube.com/channel/UC2LVhJH_9cT2XKp0VAfsKOQ --write-info-json --ignore-errors"                
~~~
{: .output}

These are the commands we need to run on our computer.

The system() function will take the input it gets, and send that to the operating
system on your computer. We do that in a for-loop:



~~~
for(i in 1:length(commands)){
  system(commands[i])
}
~~~
{: .language-r}

Et viola - videos and metadata is saved.


## Harvest results of searches


Create a vector containing search terms:

~~~
keywords <- c("Jordan Peterson Motivation",
              "Jordan Peterson Islam",
              "Jordan Peterson Postmodernism")
~~~
{: .language-r}

Again youtube-dl will do the work for us, but we still need to generate the
command for our command line. This function should do the trick:


~~~
harvest_keyword_string <- function(keywords, n=5, video=F, exe="youtube-dl.exe"){
  skip <- "--skip-download"
  if(video){skip <- ""}
  search_opt <- paste0("ytsearch", n, collapse="")
  search_terms <- stringr::str_replace_all(keywords, " ", "_")
  result <- paste0(exe, ' ', search_opt, ':"', keywords, '" ', skip, 
                     ' --write-info-json -o "%(title)s-%(id)s-keywords-',search_terms,'"')
  return(result)
}
~~~
{: .language-r}

This will process our keywords, and generate the commands we need to execute:

~~~
harvest_keyword_string(keywords)
~~~
{: .language-r}



~~~
[1] "youtube-dl.exe ytsearch5:\"Jordan Peterson Motivation\" --skip-download --write-info-json -o \"%(title)s-%(id)s-keywords-Jordan_Peterson_Motivation\""      
[2] "youtube-dl.exe ytsearch5:\"Jordan Peterson Islam\" --skip-download --write-info-json -o \"%(title)s-%(id)s-keywords-Jordan_Peterson_Islam\""                
[3] "youtube-dl.exe ytsearch5:\"Jordan Peterson Postmodernism\" --skip-download --write-info-json -o \"%(title)s-%(id)s-keywords-Jordan_Peterson_Postmodernism\""
~~~
{: .output}
By default no videos will be downloaded (video = F), and return the first 
n = 5 results. 

The function is just a way to generate more than one search. Look at the 
output, to see what the structure of the commands is. Adjust video = F and 
n=5 if needed.

Pass them to the commandline as previously shown.

  
  
{% include links.md %}
